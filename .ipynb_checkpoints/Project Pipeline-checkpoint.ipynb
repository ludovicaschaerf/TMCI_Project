{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lucovica Schaerf, Antònio Mendes, Jaël Kortekaas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large part of our code is used from: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the the preprocessing pipeline to our project. \n",
    "As a first step we are importing the data and filtering out all the songs that\n",
    "we don't need for our analysis. Secondly, we will implement the 'standard' \n",
    "pipeline and, once we obtain the most common words per each album, author, year\n",
    "(...) we will move to another file to do the clustering and topic analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.collocations import *\n",
    "from nltk.collocations import BigramAssocMeasures\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import gensim\n",
    "import spacy\n",
    "import itertools\n",
    "\n",
    "from gensim import corpora, models\n",
    "from nltk.corpus import wordnet as wn\n",
    "from operator import itemgetter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_dir = Path(\"./figures\")\n",
    "data_dir = Path(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'song', 'year', 'artist', 'genre', 'lyrics'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "songs = []\n",
    "\n",
    "with open('./data/lyrics.csv', 'r', encoding=\"utf-8\") as infile:\n",
    "    songs = pd.read_csv(infile)\n",
    "    \n",
    "print(songs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116793</th>\n",
       "      <td>116793</td>\n",
       "      <td>if-i-m-dreaming-my-life</td>\n",
       "      <td>2009</td>\n",
       "      <td>david-bowie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>VERSE (there)\\nWas she never there/here?\\nWas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116794</th>\n",
       "      <td>116794</td>\n",
       "      <td>seven</td>\n",
       "      <td>2009</td>\n",
       "      <td>david-bowie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>I forgot what my father said\\nI forgot what he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116795</th>\n",
       "      <td>116795</td>\n",
       "      <td>i-can-t-read</td>\n",
       "      <td>2009</td>\n",
       "      <td>david-bowie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>I can't read and I can't write down\\nI don't k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116796</th>\n",
       "      <td>116796</td>\n",
       "      <td>thursday-s-child</td>\n",
       "      <td>2009</td>\n",
       "      <td>david-bowie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>All of my life I've tried so hard\\nDoing my be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116797</th>\n",
       "      <td>116797</td>\n",
       "      <td>survive</td>\n",
       "      <td>2009</td>\n",
       "      <td>david-bowie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Oh, my\\nNaked eyes\\nI should have kept you\\nI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67509</th>\n",
       "      <td>67509</td>\n",
       "      <td>child-in-time</td>\n",
       "      <td>1972</td>\n",
       "      <td>deep-purple</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Sweet child in time\\nYou'll see the line\\nThe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67510</th>\n",
       "      <td>67510</td>\n",
       "      <td>deep-purple-overture</td>\n",
       "      <td>2015</td>\n",
       "      <td>deep-purple</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Good golly, said little miss molly\\nWhen she w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67517</th>\n",
       "      <td>67517</td>\n",
       "      <td>paint-it-black</td>\n",
       "      <td>2015</td>\n",
       "      <td>deep-purple</td>\n",
       "      <td>Rock</td>\n",
       "      <td>I see a red door and I want it painted black,\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67523</th>\n",
       "      <td>67523</td>\n",
       "      <td>anyone-s-daughter</td>\n",
       "      <td>2014</td>\n",
       "      <td>deep-purple</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Well, I stood under your bedroom window, throw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67524</th>\n",
       "      <td>67524</td>\n",
       "      <td>perfect-strangers</td>\n",
       "      <td>2014</td>\n",
       "      <td>deep-purple</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Can you remember remember my name\\nAs I flow t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1551 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                     song  year       artist genre  \\\n",
       "116793  116793  if-i-m-dreaming-my-life  2009  david-bowie  Rock   \n",
       "116794  116794                    seven  2009  david-bowie  Rock   \n",
       "116795  116795             i-can-t-read  2009  david-bowie  Rock   \n",
       "116796  116796         thursday-s-child  2009  david-bowie  Rock   \n",
       "116797  116797                  survive  2009  david-bowie  Rock   \n",
       "...        ...                      ...   ...          ...   ...   \n",
       "67509    67509            child-in-time  1972  deep-purple  Rock   \n",
       "67510    67510     deep-purple-overture  2015  deep-purple  Rock   \n",
       "67517    67517           paint-it-black  2015  deep-purple  Rock   \n",
       "67523    67523        anyone-s-daughter  2014  deep-purple  Rock   \n",
       "67524    67524        perfect-strangers  2014  deep-purple  Rock   \n",
       "\n",
       "                                                   lyrics  \n",
       "116793  VERSE (there)\\nWas she never there/here?\\nWas ...  \n",
       "116794  I forgot what my father said\\nI forgot what he...  \n",
       "116795  I can't read and I can't write down\\nI don't k...  \n",
       "116796  All of my life I've tried so hard\\nDoing my be...  \n",
       "116797  Oh, my\\nNaked eyes\\nI should have kept you\\nI ...  \n",
       "...                                                   ...  \n",
       "67509   Sweet child in time\\nYou'll see the line\\nThe ...  \n",
       "67510   Good golly, said little miss molly\\nWhen she w...  \n",
       "67517   I see a red door and I want it painted black,\\...  \n",
       "67523   Well, I stood under your bedroom window, throw...  \n",
       "67524   Can you remember remember my name\\nAs I flow t...  \n",
       "\n",
       "[1551 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists = ['bruce-springsteen', 'elliot-smith', 'black-sabbath', 'deep-purple', 'david-bowie']\n",
    "\n",
    "david_bowie = songs[songs[u'artist'] == 'david-bowie']\n",
    "black_sabbath = songs[songs[u'artist'] == 'black-sabbath']\n",
    "bruce_springsteen = songs[songs[u'artist'] == 'bruce-springsteen']\n",
    "elliot_smith = songs[songs[u'artist'] == 'elliot-smith']\n",
    "deep_purple = songs[songs[u'artist'] == 'deep-purple']\n",
    "\n",
    "lyrics = pd.concat([david_bowie, black_sabbath, bruce_springsteen, elliot_smith, deep_purple], axis=0)\n",
    "lyrics = lyrics.dropna()\n",
    "lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['oh', 'yeah', 'hey', 'doo', 'oo', 'uh', 'la', 'verse', 'chorus', 'bridge', 'x2', \"'m\", 'da', 'ooh', 'aaaahh', 'ooo', 'duh', 'whop', 'u', 'ah', 'na', 'whoa', 'ai', \"n't\", 'wa', 'gon', \"'ll\", 'gon', \"'d\", \"'re\", \"'ve\", \"'em\", \"'\", 'ca', 'ha', 'wo', 'wir', 'wan', 'doe', 'well', 'sha', 'ya', 'ta', \"'cause\", \"`\"]) # filter out common meaningless words/sounds and words describing song structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing pipeline we decided to implement includes the following steps:\n",
    "- filtering out stopwords, puntuation, sounds typical from songs\n",
    "- lemmatizing\n",
    "- adding the most common bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['verse-NOUN',\n",
       " 'air-NOUN',\n",
       " 'time-NOUN',\n",
       " 'flower-NOUN',\n",
       " 'gallery-NOUN',\n",
       " 'hymn-NOUN',\n",
       " 'night-NOUN',\n",
       " 'chorus-NOUN',\n",
       " 'time-NOUN',\n",
       " 'day-NOUN',\n",
       " 'light-NOUN',\n",
       " 'life-NOUN',\n",
       " 'time-NOUN',\n",
       " 'chance-NOUN',\n",
       " 'mother-NOUN',\n",
       " 'father-NOUN',\n",
       " 'step-NOUN',\n",
       " 'time-NOUN',\n",
       " 'verse-NOUN',\n",
       " 'chorus-NOUN',\n",
       " 'life-NOUN',\n",
       " 'life-NOUN',\n",
       " 'life-NOUN',\n",
       " 'dreaming-NOUN',\n",
       " 'life-NOUN',\n",
       " 'life-NOUN',\n",
       " 'repeat-NOUN',\n",
       " 'life-NOUN',\n",
       " 'dreaming-NOUN',\n",
       " 'life-NOUN',\n",
       " 'come-VERB_to-PRT',\n",
       " 'fade-VERB_now-ADV',\n",
       " 'father-NOUN_step-NOUN',\n",
       " 'flower-NOUN_so-ADV',\n",
       " 'gallery-NOUN_with-ADP',\n",
       " 'hymn-NOUN_of-ADP',\n",
       " 'it-PRON_air-NOUN',\n",
       " 'just-ADV_one-NUM',\n",
       " 'live-VERB_chance-NOUN',\n",
       " 'mother-NOUN_sigh-VERB',\n",
       " 'never-ADV_there/here-DET',\n",
       " 'night-NOUN_sing-VERB',\n",
       " 'of-ADP_night-NOUN',\n",
       " 'one-NUM_live-VERB',\n",
       " 'sing-VERB_come-VERB',\n",
       " 'so-ADV_from-ADP',\n",
       " 'step-NOUN_aside-ADV',\n",
       " 'to-PRT_me-PRON',\n",
       " 'x2-ADP_second-ADJ',\n",
       " 'chance-NOUN_when-ADV']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "bigram_measures = BigramAssocMeasures()\n",
    "un2wn_mapping = {\"VERB\" : wn.VERB, \"NOUN\" : wn.NOUN, \"ADJ\" : wn.ADJ, \"ADV\" : wn.ADV}\n",
    "\n",
    "def convertTuple(tup): \n",
    "    str =  '_'.join(tup) \n",
    "    return str\n",
    "  \n",
    "def simple_preprocess(lyrics, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    lyricslist = [re.sub('\\-', '', str(lyric)) for lyric in lyrics['lyrics'].tolist()] # take out all hyphens that often connect meaningless words/sounds to these stopwords can be filtered out later\n",
    "    lyricslist = [re.sub('[\\.\\,\\?,\\!,\\(,\\),\\:,\\\",\\[,\\]]', '', str(lyric)) for lyric in lyricslist] # take out all punctuation\n",
    "    lyricslist = [word_tokenize(lyric.lower()) for lyric in lyricslist]\n",
    "    finder = []\n",
    "    for i,lyric in enumerate(lyricslist):\n",
    "        for j,tup in enumerate(nltk.pos_tag(lyric, tagset=\"universal\")):\n",
    "            token = \"-\".join([tup[0], tup[1]])\n",
    "            if token.split(\"-\")[-1] in un2wn_mapping.keys():\n",
    "                lyricslist[i][j] = \"-\".join([wnl.lemmatize(str(token.split(\"-\")[0]), pos = un2wn_mapping[token.split(\"-\")[-1]]), token.split(\"-\")[-1]])\n",
    "            else:\n",
    "                lyricslist[i][j] = \"-\".join([wnl.lemmatize(str(token.split(\"-\")[0])),token.split(\"-\")[-1]]) \n",
    "        lyricslist[i] = [word for word in lyric if word.split(\"-\")[0] not in stop_words]\n",
    "        finder.append(BigramCollocationFinder.from_words(lyric))\n",
    "        finder[i] = finder[i].nbest(bigram_measures.pmi, 20)\n",
    "        finder[i] = [convertTuple(x) for x in finder[i]] #need to append the two words back together\n",
    "        lyricslist[i] = [word for word in lyric if word.split(\"-\")[-1] == \"NOUN\"]\n",
    "        lyricslist[i] = lyricslist[i] + finder[i]\n",
    "    lyrics['bag_of_words'] = lyricslist\n",
    "\n",
    "\n",
    "simple_preprocess(lyrics)\n",
    "example = lyrics['bag_of_words'][116793]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 27851\n"
     ]
    }
   ],
   "source": [
    "#count how many times a word appears --> give a document\n",
    "#lyrics['bag_of_words']\n",
    "\n",
    "list_BOWlyrics = [[]]\n",
    "for lyric in lyrics['bag_of_words']:\n",
    "    list_BOWlyrics += [lyric]\n",
    "\n",
    "lyrics_dictionary = corpora.Dictionary(list_BOWlyrics)\n",
    "print('Number of unique tokens:', len(lyrics_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'air-NOUN': 0, 'chance-NOUN': 1, 'chance-NOUN_when-ADV': 2, 'chorus-NOUN': 3, 'come-VERB_to-PRT': 4, 'day-NOUN': 5, 'dreaming-NOUN': 6, 'fade-VERB_now-ADV': 7, 'father-NOUN': 8, 'father-NOUN_step-NOUN': 9, 'flower-NOUN': 10, 'flower-NOUN_so-ADV': 11}\n",
      "word with id 8: father-NOUN\n",
      "frequency of token 8: 43\n"
     ]
    }
   ],
   "source": [
    "print(dict(itertools.islice(lyrics_dictionary.token2id.items(), 12)))\n",
    "print(\"word with id 8:\", lyrics_dictionary[8])\n",
    "print(\"frequency of token 8:\", lyrics_dictionary.dfs[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 8343\n"
     ]
    }
   ],
   "source": [
    "# Filter out words that occur in less than 5 documents, or more than 70% of the documents.\n",
    "lyrics_dictionary.filter_extremes(no_below=2, no_above=0.3)\n",
    "print('Number of unique tokens:', len(lyrics_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-words representation of the documents\n",
    "lyrics_bow_corpus = [lyrics_dictionary.doc2bow(d) for d in list_BOWlyrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 2), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 8), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 2)]\n"
     ]
    }
   ],
   "source": [
    "# the BOW representation of the first document\n",
    "print(lyrics_bow_corpus[1][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "life-NOUN --> 8\n",
      "chorus-NOUN --> 2\n",
      "dreaming-NOUN --> 2\n",
      "verse-NOUN --> 2\n",
      "air-NOUN --> 1\n",
      "chance-NOUN --> 1\n",
      "come-VERB_to-PRT --> 1\n",
      "day-NOUN --> 1\n",
      "father-NOUN --> 1\n",
      "flower-NOUN --> 1\n",
      "gallery-NOUN --> 1\n",
      "hymn-NOUN --> 1\n",
      "just-ADV_one-NUM --> 1\n",
      "light-NOUN --> 1\n",
      "mother-NOUN --> 1\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# which words (and how often) appear in the first document?\n",
    "for i, freq in sorted(lyrics_bow_corpus[1], key=itemgetter(1), reverse=True)[:15]:\n",
    "    print(lyrics_dictionary[i], \"-->\", freq)\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_ldamodel = models.ldamodel.LdaModel(lyrics_bow_corpus, num_topics=10, id2word = lyrics_dictionary, passes=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('da-NOUN', 0.038209487),\n",
       "   ('baby-NOUN', 0.023037024),\n",
       "   ('somebody-NOUN', 0.018633816),\n",
       "   ('love-NOUN', 0.015927922),\n",
       "   ('whoa-NOUN', 0.015855681),\n",
       "   ('yeah-NOUN', 0.0112876445),\n",
       "   ('man-NOUN', 0.011008566),\n",
       "   ('way-NOUN', 0.009823215),\n",
       "   ('eye-NOUN', 0.0093977805),\n",
       "   ('boot-NOUN', 0.0052265404),\n",
       "   ('mind-NOUN', 0.0051820143),\n",
       "   ('style-NOUN', 0.0051124296),\n",
       "   ('hey-NOUN', 0.0050349906),\n",
       "   ('fool-NOUN', 0.0050342097),\n",
       "   ('world-NOUN', 0.004933279)]),\n",
       " (1,\n",
       "  [('love-NOUN', 0.055522867),\n",
       "   ('thing-NOUN', 0.025577333),\n",
       "   ('way-NOUN', 0.0125366775),\n",
       "   ('fire-NOUN', 0.01136626),\n",
       "   ('life-NOUN', 0.011214286),\n",
       "   ('baby-NOUN', 0.009950187),\n",
       "   ('ground-NOUN', 0.009311527),\n",
       "   ('day-NOUN', 0.008648619),\n",
       "   ('eye-NOUN', 0.007957869),\n",
       "   ('home-NOUN', 0.007954745),\n",
       "   ('heart-NOUN', 0.007518441),\n",
       "   ('man-NOUN', 0.0073767006),\n",
       "   ('sound-NOUN', 0.0073655765),\n",
       "   ('boy-NOUN', 0.00577361),\n",
       "   ('world-NOUN', 0.0056224666)]),\n",
       " (2,\n",
       "  [('train-NOUN', 0.0198593),\n",
       "   ('home-NOUN', 0.016938752),\n",
       "   ('bring-NOUN', 0.013427475),\n",
       "   ('day-NOUN', 0.012881562),\n",
       "   ('people-NOUN', 0.011208521),\n",
       "   ('woman-NOUN', 0.009879562),\n",
       "   ('ah-NOUN', 0.009861031),\n",
       "   ('hero-NOUN', 0.008205215),\n",
       "   ('shine-NOUN', 0.008194698),\n",
       "   ('game-NOUN', 0.007807175),\n",
       "   ('star-NOUN', 0.0075394874),\n",
       "   ('fool-NOUN', 0.007460955),\n",
       "   ('man-NOUN', 0.006669031),\n",
       "   ('war-NOUN', 0.0061569344),\n",
       "   ('zane-NOUN', 0.005934515)]),\n",
       " (3,\n",
       "  [('hand-NOUN', 0.028434489),\n",
       "   ('thing-NOUN', 0.01918368),\n",
       "   ('let-NOUN', 0.016843272),\n",
       "   ('come-NOUN', 0.014572862),\n",
       "   ('rock-NOUN', 0.01400022),\n",
       "   ('duh-NOUN', 0.010929923),\n",
       "   ('way-NOUN', 0.0105206305),\n",
       "   ('eye-NOUN', 0.008600817),\n",
       "   ('rise-NOUN', 0.006193539),\n",
       "   ('one-NOUN', 0.0061396104),\n",
       "   ('sky-NOUN', 0.0061135036),\n",
       "   ('friend-NOUN', 0.005949675),\n",
       "   ('street-NOUN', 0.005707416),\n",
       "   ('tonight-NOUN', 0.0052232565),\n",
       "   ('head-NOUN', 0.0052192765)]),\n",
       " (4,\n",
       "  [('nothing-NOUN', 0.018760914),\n",
       "   ('girl-NOUN', 0.018152012),\n",
       "   ('eye-NOUN', 0.013881776),\n",
       "   ('baby-NOUN', 0.010751656),\n",
       "   ('oh-NOUN', 0.010609668),\n",
       "   ('man-NOUN', 0.01040569),\n",
       "   ('day-NOUN', 0.010072426),\n",
       "   ('god-NOUN', 0.010012877),\n",
       "   ('name-NOUN', 0.009953347),\n",
       "   ('life-NOUN', 0.0094954),\n",
       "   ('someone-NOUN', 0.00938252),\n",
       "   ('heart-NOUN', 0.008469157),\n",
       "   ('mind-NOUN', 0.008357067),\n",
       "   ('love-NOUN', 0.007693735),\n",
       "   ('ba-NOUN', 0.0071494286)]),\n",
       " (5,\n",
       "  [('heart-NOUN', 0.016061803),\n",
       "   ('fame-NOUN', 0.015660759),\n",
       "   ('aaaahh-NOUN', 0.012587602),\n",
       "   ('year-NOUN', 0.008647463),\n",
       "   ('wind-NOUN', 0.008306092),\n",
       "   ('world-NOUN', 0.008048329),\n",
       "   ('ooo-NOUN', 0.007970194),\n",
       "   ('eye-NOUN', 0.00764322),\n",
       "   ('man-NOUN', 0.006206448),\n",
       "   ('side-NOUN', 0.0061840797),\n",
       "   ('aahh-NOUN', 0.005881597),\n",
       "   ('name-NOUN', 0.0054479996),\n",
       "   ('face-NOUN', 0.0050426545),\n",
       "   ('girl-NOUN', 0.00496757),\n",
       "   ('town-NOUN', 0.0047939597)]),\n",
       " (6,\n",
       "  [('dance-NOUN', 0.033576846),\n",
       "   ('baby-NOUN', 0.023245608),\n",
       "   ('world-NOUN', 0.016448764),\n",
       "   ('city-NOUN', 0.015516479),\n",
       "   ('town-NOUN', 0.013968683),\n",
       "   ('yeah-NOUN', 0.011471925),\n",
       "   ('ho-NOUN', 0.010827301),\n",
       "   ('love-NOUN', 0.010229438),\n",
       "   ('home-NOUN', 0.009417946),\n",
       "   ('man-NOUN', 0.009299998),\n",
       "   ('jump-NOUN', 0.008549644),\n",
       "   ('money-NOUN', 0.008216994),\n",
       "   ('babe-NOUN', 0.007665469),\n",
       "   ('hey-NOUN', 0.007537927),\n",
       "   ('miracle-NOUN', 0.0074419845)]),\n",
       " (7,\n",
       "  [('day-NOUN', 0.023856375),\n",
       "   ('girl-NOUN', 0.016539957),\n",
       "   ('way-NOUN', 0.01618249),\n",
       "   ('life-NOUN', 0.015856246),\n",
       "   ('heart-NOUN', 0.012254043),\n",
       "   ('light-NOUN', 0.010045728),\n",
       "   ('street-NOUN', 0.009702639),\n",
       "   ('yeah-NOUN', 0.008906853),\n",
       "   ('everything-NOUN', 0.008688574),\n",
       "   ('boy-NOUN', 0.008492804),\n",
       "   ('shot-NOUN', 0.007632102),\n",
       "   ('sky-NOUN', 0.0071008727),\n",
       "   ('eye-NOUN', 0.0067488076),\n",
       "   ('doo-NOUN', 0.0065851137),\n",
       "   ('world-NOUN', 0.006319988)]),\n",
       " (8,\n",
       "  [('yeah-NOUN', 0.017476914),\n",
       "   ('sex-NOUN', 0.013712263),\n",
       "   ('today-NOUN', 0.011105127),\n",
       "   ('daddy-NOUN', 0.010392823),\n",
       "   ('day-NOUN', 0.009937404),\n",
       "   ('eye-NOUN', 0.00922316),\n",
       "   ('ooh-NOUN', 0.008486645),\n",
       "   ('church-NOUN', 0.008338581),\n",
       "   ('love-NOUN', 0.008143569),\n",
       "   ('cain-NOUN', 0.007883579),\n",
       "   ('something-NOUN', 0.0073084286),\n",
       "   ('life-NOUN', 0.006852676),\n",
       "   ('adam-NOUN', 0.0064738705),\n",
       "   ('hold-NOUN', 0.006458455),\n",
       "   ('face-NOUN', 0.006299173)]),\n",
       " (9,\n",
       "  [('man-NOUN', 0.032778542),\n",
       "   ('dream-NOUN', 0.025355516),\n",
       "   ('woman-NOUN', 0.011242257),\n",
       "   ('life-NOUN', 0.01071768),\n",
       "   ('baby-NOUN', 0.010715974),\n",
       "   ('place-NOUN', 0.010236889),\n",
       "   ('yeah-NOUN', 0.009555439),\n",
       "   ('eye-NOUN', 0.009344765),\n",
       "   ('road-NOUN', 0.008292597),\n",
       "   ('mary-NOUN', 0.0076983958),\n",
       "   ('home-NOUN', 0.0076069883),\n",
       "   ('dog-NOUN', 0.0070233666),\n",
       "   ('johnny-NOUN', 0.0064492994),\n",
       "   ('friend-NOUN', 0.0062909815),\n",
       "   ('hand-NOUN', 0.0062291096)])]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the setting formatted=False allows you to get rid of the word*probability format when retrieveing topics\n",
    "lyrics_ldamodel.show_topics(formatted=False, num_words=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import nltk.corpus\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from gensim import corpora, models\n",
    "from nltk.corpus import wordnet as wn\n",
    "from operator import itemgetter\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics, manifold\n",
    "import scipy\n",
    "from scipy import cluster\n",
    "import matplotlib as mpl \n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
